{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"KnowledgeGraph_P5.ipynb","provenance":[],"authorship_tag":"ABX9TyPEXCIc9DBirnSOk+uDY5BA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Data Abstraction\n","Now we focus on the 'cs' category. We record the monthly number of submitted papers belonging to the cs category. "],"metadata":{"id":"pz-Ds8wC18h4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"R_YeW_c-3sf3"},"outputs":[],"source":["## 大规模抽取data里cs种类的信息"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","import os\n","path=\"/content/drive/My Drive/Research/Data/\"\n","\n","os.chdir(path)\n","os.listdir(path)"],"metadata":{"id":"rKpu4_oc3u35","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645803145285,"user_tz":-480,"elapsed":23875,"user":{"displayName":"CUI TENGFEI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310385898916684610"}},"outputId":"d38d80be-083c-426f-c548-82800cdf591a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]},{"output_type":"execute_result","data":{"text/plain":["['english.txt',\n"," '2019_2020_all_data_final.csv',\n"," '2014_abs',\n"," '2015_abs',\n"," '2016_abs',\n"," '2017_abs',\n"," '2018_abs',\n"," 'My_Process',\n"," 'all_data_statistic.csv',\n"," 'top_category_details.csv',\n"," 'top5_statistic_months.csv',\n"," 'top5_statistics_col_1.csv',\n"," 'cs_summary',\n"," 'My_result']"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import re"],"metadata":{"id":"XYkL-QPV3u6N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## 定义抽取类别的函数\n","#抽取category信息\n","#input:text  output:category字符串，若input是dirty data,返回none\n","def cat_processor(text):\n","  result=''\n","  if type(text) != float :\n","    if(text!='subject/category'):\n","      for cat in text.split(\";\"):\n","        cat=cat.strip()\n","        result = cat.split('(')[1].split(')')[0].split('.')[0]\n","    else:\n","      result='none'\n","  else:\n","    result ='none'\n","  return  result\n","\n","#抽取日期信息\n","#input：text  output:日期，若input为dirty data,返回none\n","def Date_processor(text):\n","  year='none'\n","  month='none'\n","  if type(text) != float:\n","    list_text=text.split()\n","    if len(list_text) > 5:\n","      year= list_text[-5]\n","      month=list_text[-6]\n","  return year,month\n","\n","\n","# 定义提取摘要函数\n","#input: data:要统计的数据   cat_name:统计量（种类）   return: summary_data： input的特定种类的信息\n","def summary_processor(data,cat_name,year):\n","  result =pd.DataFrame(columns=['origin','link','authors','summary','category','Date'])\n","  for index in range(len(data['summary'])):\n","    row_info = data.loc[index]\n","    category = row_info[0]\n","    Date = row_info[1]\n","\n","    #print(category)\n","    #print(Date)\n","    category = cat_processor(category)\n","    sample_year,smaple_month = Date_processor(Date)\n","\n","    if category!='none' :\n","      if category == cat_name:\n","        if year == sample_year:\n","          #print(row_info)\n","          result = result.append(row_info,ignore_index=True)\n","          #print(result)\n","  return result\n"],"metadata":{"id":"9MvV7CCs3u8a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 标定读取数据\n","docname_2014 =['arxiv_2014_half1_p1','arxiv_2014_half1_p2','arxiv_2014_half1_p3',\n","               'arxiv_2014_half1_p4','arxiv_2014_half1_p5','arxiv_2014_half1_p6',\n","               'arxiv_2014_half1_p7','arxiv_2014_half1_p8','arxiv_2014_half1_p9',\n","               'arxiv_2014_half2_p1','arxiv_2014_half2_p2','arxiv_2014_half2_p3',\n","               'arxiv_2014_half2_p4','arxiv_2014_half2_p5','arxiv_2014_half2_p6']\n","\n","docname_2015 =['arxiv_2015_p1','arxiv_2015_p2','arxiv_2015_p3','arxiv_2015_p4',\n","               'arxiv_2015_p5','arxiv_2015_p6','arxiv_2015_p7','arxiv_2015_p8',\n","               'arxiv_2015_p9']\n","\n","docname_2016=['arxiv_2016_p1','arxiv_2016_p2','arxiv_2016_p3','arxiv_2016_p4',\n","              'arxiv_2016_p5','arxiv_2016_p6','arxiv_2016_p7','arxiv_2016_p8',\n","              'arxiv_2016_p9','arxiv_2016_p10']\n","\n","docname_2017 = ['2017-1','2017-2','2017-3','2017-4','2017-5','2017-6','2017-7',\n","                '2017-8']\n","\n","docname_2018 =['arxiv_2018_half1_p1','arxiv_2018_half1_p2','arxiv_2018_half1_p3',\n","               'arxiv_2018_half1_p4','arxiv_2018_half1_p5','arxiv_2018_half1_p6',\n","               'arxiv_2018_half1_p7','arxiv_2018_half2_p1','arxiv_2018_half2_p2',\n","               'arxiv_2018_half2_p3','arxiv_2018_half2_p4','arxiv_2018_half2_p5',\n","               'arxiv_2018_half2_p6','arxiv_2018_half2_p7']\n","\n","docname_2019 = ['2019_2020_all_data_final']"],"metadata":{"id":"-yAuORvjwEvP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cat_name = 'cs'\n","\n","# summary data for 2014\n","year_2014='2014'\n","summary_2014 = pd.DataFrame(columns=['origin','link','authors','summary','category','Date'])\n","for document in docname_2014:\n","  data = pd.read_csv(path+'2014_abs/'+document+'.csv',usecols=[0,1,2,3,4,8],\n","                     encoding='ISO-8859-1',header=None,names=['origin','link','authors','summary','category','Date'])\n","  summary = summary_processor(data,cat_name,year_2014)\n","  summary_2014 = pd.concat([summary_2014,summary])\n","summary_2014.to_csv(path+'My_Process/Summary_2014.csv',index=False)\n","\n","# summary data for 2015\n","year_2015='2015'\n","summary_2015 = pd.DataFrame(columns=['origin','link','authors','summary','category','Date'])\n","for document in docname_2015:\n","  data = pd.read_csv(path+'2015_abs/'+document+'.csv',usecols=[0,1,2,3,4,8],\n","                     encoding='ISO-8859-1',header=None,names=['origin','link','authors','summary','category','Date'])\n","  summary = summary_processor(data,cat_name,year_2015)\n","  summary_2015 = pd.concat([summary_2015,summary])\n","summary_2015.to_csv(path+'My_Process/Summary_2015.csv',index=False)\n","\n","# summary data for 2016\n","year_2016='2016'\n","summary_2016 = pd.DataFrame(columns=['origin','link','authors','summary','category','Date'])\n","for document in docname_2016:\n","  data = pd.read_csv(path+'2016_abs/'+document+'.csv',usecols=[0,1,2,3,4,8],\n","                     encoding='ISO-8859-1',header=None,names=['origin','link','authors','summary','category','Date'])\n","  summary = summary_processor(data,cat_name,year_2016)\n","  summary_2016 = pd.concat([summary_2016,summary])\n","summary_2016.to_csv(path+'My_Process/Summary_2016.csv',index=False)\n","\n","# summary data for 2017\n","year_2017='2017'\n","summary_2017 = pd.DataFrame(columns=['origin','link','authors','summary','category','Date'])\n","for document in docname_2017:\n","  data = pd.read_csv(path+'2017_abs/'+document+'.csv',usecols=[0,1,2,3,4,8],\n","                     encoding='ISO-8859-1',header=None,names=['origin','link','authors','summary','category','Date'])\n","  summary = summary_processor(data,cat_name,year_2017)\n","  summary_2017 = pd.concat([summary_2017,summary])\n","summary_2017.to_csv(path+'My_Process/Summary_2017.csv',index=False)\n","\n","# summary data for 2018\n","year_2018='2018'\n","summary_2018 = pd.DataFrame(columns=['origin','link','authors','summary','category','Date'])\n","for document in docname_2018:\n","  data = pd.read_csv(path+'2018_abs/'+document+'.csv',usecols=[0,1,2,3,4,8],\n","                     encoding='ISO-8859-1',header=None,names=['origin','link','authors','summary','category','Date'])\n","  summary = summary_processor(data,cat_name,year_2018)\n","  summary_2018 = pd.concat([summary_2018,summary])\n","summary_2018.to_csv(path+'My_Process/Summary_2018.csv',index=False)\n","\n","# summary data for 2019\n","year_2019='2019'\n","summary_2019 = pd.DataFrame(columns=['origin','link','authors','summary','category','Date'])\n","for document in docname_2019:\n","  data = pd.read_csv(path+'2019_abs/'+document+'.csv',usecols=[0,1,2,3,4,8],\n","                     encoding='ISO-8859-1',header=None,names=['origin','link','authors','summary','category','Date'])\n","  summary = summary_processor(data,cat_name,year_2019)\n","  summary_2019 = pd.concat([summary_2019,summary])\n","summary_2019.to_csv(path+'My_Process/Summary_2019.csv',index=False)\n","\n","# summary data for 2020\n","year_2020='2020'\n","summary_2020 = pd.DataFrame(columns=['origin','link','authors','summary','category','Date'])\n","for document in docname_2019:\n","  data = pd.read_csv(path+'2019_abs/'+document+'.csv',usecols=[0,1,2,3,4,8],\n","                     encoding='ISO-8859-1',header=None,names=['origin','link','authors','summary','category','Date'])\n","  summary = summary_processor(data,cat_name,year_2020)\n","  summary_2020 = pd.concat([summary_2020,summary])\n","summary_2020.to_csv(path+'My_Process/Summary_2020.csv',index=False)\n"],"metadata":{"id":"7MdPDmCs3u_l","colab":{"base_uri":"https://localhost:8080/","height":381},"executionInfo":{"status":"error","timestamp":1642946363660,"user_tz":-480,"elapsed":375647,"user":{"displayName":"CUI TENGFEI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12310385898916684610"}},"outputId":"ec001a7d-8f60-44d2-e030-a8d189b605db"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-4c3969313cec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocname_2019\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   data = pd.read_csv(path+'2019_abs/'+document+'.csv',usecols=[0,1,2,3,4,8],\n\u001b[0;32m---> 58\u001b[0;31m                      encoding='ISO-8859-1',header=None,names=['origin','link','authors','summary','category','Date'])\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcat_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myear_2019\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0msummary_2019\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msummary_2019\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1991\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m                 \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Research/Data/2019_abs/2019_2020_all_data_final.csv'"]}]},{"cell_type":"code","source":["# summary data for 2019\n","year_2019='2019'\n","summary_2019 = pd.DataFrame(columns=['origin','link','authors','summary','category','Date'])\n","for document in docname_2019:\n","  data = pd.read_csv(path+document+'.csv',usecols=[0,1,2,3,4,8],\n","                     encoding='ISO-8859-1',header=None,names=['origin','link','authors','summary','category','Date'])\n","  summary = summary_processor(data,cat_name,year_2019)\n","  summary_2019 = pd.concat([summary_2019,summary])\n","summary_2019.to_csv(path+'My_Process/Summary_2019.csv',index=False)\n","\n","# summary data for 2020\n","year_2020='2020'\n","summary_2020 = pd.DataFrame(columns=['origin','link','authors','summary','category','Date'])\n","for document in docname_2019:\n","  data = pd.read_csv(path+document+'.csv',usecols=[0,1,2,3,4,8],\n","                     encoding='ISO-8859-1',header=None,names=['origin','link','authors','summary','category','Date'])\n","  summary = summary_processor(data,cat_name,year_2020)\n","  summary_2020 = pd.concat([summary_2020,summary])\n","summary_2020.to_csv(path+'My_Process/Summary_2020.csv',index=False)\n"],"metadata":{"id":"Jzi4Uocn3vLi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"oq1qrS-o3vOS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"b4NG6wI23vRM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"N4Aql2z43vUF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"WZ0MwHiI3vWy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"IT8H2O8U3vZp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"VihmQFd-3vcV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"HlZd8dMu3vew"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"ygURQPes3vhW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"v6NpYidN3vjz"},"execution_count":null,"outputs":[]}]}